日常记录
20190226:首次登陆服务器。为服务器个人目录安装miniconda以及毕业设计需要的包环境。学会在服务器上网。
20190227:下载毕业设计所需数据。搭建bert服务器。
20190228:分析Marco以及record数据集，尝试下载narrativeQA数据集。开始写classification代码。
20190301:调试bert服务器。确认不实用nltk（太慢了）。加载marco的时候不用bert，在训练的时候用bert。考虑如何改进marco数据的存储方式。加入BiDAF。
20190302:基本完成分类代码。实现class balanced cross-entropy。模型跑起来了。不知道最后的结果，loss下降不明显（可能数据过于稀疏）。
20190303:开始着手开发ptr-generator模型。然后今天放假……肝不动了。写开题报告以及任务书。
20190304:分析Marco数据集的common sense部分，得出结论，Marco无需common sense。
20190305:思考如何优化模型，没有太好的思路。思考如何开发ptr-generator。
20190306:开发seq2seq with attention模型，开发到context vector之前。
20190307:完成开发seq2seq with attention模型，我真是个天才。放弃大glove，词太多了，使用小glove。完善开题报告以及任务书。
20190308:过三八妇女节。
20190309:准备并完成哥伦比亚大学的面试。
20190310:开发ptr generator network，等待计算p(w)
20190311:完成ptr generator network。p(w)：将pvocab与at concat之后，来求。在读入Marco的时候对answer编码进行扩充。将OOV的index计算出来。
20190312:优化Marco存储。[ [paragraph k], [query], [answer], [label k], [answer index]]
20190313:获得自己的词表（词频统计）。

接下来任务：
计算自己的小词表。
再开发一个ptr。
如何优化模型，现在的模型太大了。如何精简？
