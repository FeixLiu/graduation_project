日常记录
20190226:首次登陆服务器。为服务器个人目录安装miniconda以及毕业设计需要的包环境。学会在服务器上网。
20190227:下载毕业设计所需数据。搭建bert服务器。
20190228:分析Marco以及record数据集，尝试下载narrativeQA数据集。开始写classification代码。
20190301:调试bert服务器。确认不实用nltk（太慢了）。加载marco的时候不用bert，在训练的时候用bert。考虑如何改进marco数据的存储方式。加入BiDAF。
20190302:基本完成分类代码。实现class balanced cross-entropy。模型跑起来了。不知道最后的结果，loss下降不明显（可能数据过于稀疏）。
20190303:开始着手开发ptr-generator模型。然后今天放假……肝不动了。写开题报告以及任务书。
20190304:分析Marco数据集的common sense部分，得出结论，Marco无需common sense。
20190305:思考如何优化模型，没有太好的思路。思考如何开发ptr-generator。
20190306:开发seq2seq with attention模型，开发到context vector之前。
20190307:完成开发seq2seq with attention模型，我真是个天才。放弃大glove，词太多了，使用小glove。完善开题报告以及任务书。
20190308:过三八妇女节。
20190309:准备并完成哥伦比亚大学的面试。
20190310:开发ptr generator network，等待计算p(w)
20190311:完成ptr generator network。p(w)：将pvocab与at concat之后，来求。在读入Marco的时候对answer编码进行扩充。将OOV的index计算出来。
20190312:优化Marco存储。[[paragraph k], [query], [answer], [label k], [answer index], [answer word]]
20190313:获得自己的词表（词频统计）。
20190314:建立bidaf_classification的精简版。
20190315:实现valid paragraph的提取，开始着手优化ptr generator networks。
20190316:向bidaf classification中加入tensorboard的可视化以及模型的saver。继续完善generator network，LOSS计算有问题。
20190317:重构generator network的computational graph。
20190318:生成网络的输入读入。加入tf.while_loop的API。生成网络测试可运行。
20190319:添加BiLSTM到分类。思考如何使用tf.data.dataset并行数据读入。
20190320:预处理marco数据集，将所有的bert embedding加载出来。（无法一次处理完，分批次处理，每一个处理30000个数据），不可行，太大了。
20190321:解决tensorflow占用显存太多的问题。解决效率低的问题（把bert和模型放在一张卡上）。重新开始跑分类模型。画模型图。
20190322:暂时不使用bert。重回glove。开始跑分类模型。加载marco的answer与answer words时候需要改进。
20190323:研究cudnn的使用方法。将bilstm换成cudnn_lstm来提升效率。
20190324:修改生成网络的代码。生成网络的loss使用stack代替。
20190325:修改生成网络的embedding获取。测试生成网络个部分的工作效果。我驾驭不了coverage！！！！！！！！！！太难了！！！！！！！！
20190326:完成没有coverage的生成网络开发。
20190327:把分类模型以及生成模型联合在一起。
20190328:调整昨天和在一起的模型。生成网络有问题！！！！！！！不知道问题在哪里。

接下来：
查看各placeholder的准备输入是否正确。检测loss与answer pre是否正确。
生成网络的loss，acc可视化。
优化分类模型。
实现transformer
